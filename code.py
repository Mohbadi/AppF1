# -*- coding: utf-8 -*-
"""Code

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aTDw9fXRvtWflmuXWxD0U9jRLHtSeDE6

# Data importation
"""



#Précisez le chemin vers votre répertoire contenant le fichier
DATA_DIR   = '/content/drive/MyDrive/Mémoire F1/f1db_csv/'
DATA_DIR

import requests
from bs4 import BeautifulSoup
from io import StringIO

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go

df_circuit = pd.read_csv('circuits.csv')
df_constructor_result = pd.read_csv('constructor_results.csv')
df_constructor_standing = pd.read_csv('constructor_standings.csv')
df_constructor = pd.read_csv('constructors.csv')
df_driver_standing = pd.read_csv('driver_standings.csv')
df_drivers = pd.read_csv('drivers.csv')
df_drivers["Driver_name"] = df_drivers["forename"] + ' ' + df_drivers['surname']
df_lap_times = pd.read_csv('lap_times.csv')
df_pit_stops = pd.read_csv('pit_stops.csv')
df_qualifying = pd.read_csv('qualifying.csv')
df_races = pd.read_csv('races.csv')
df_results = pd.read_csv('results.csv')
df_seasons = pd.read_csv('seasons.csv')
df_sprint_results = pd.read_csv('sprint_results.csv')
df_status = pd.read_csv('status.csv')

df_final = pd.read_csv('df_final_2.csv')
"""# Scraping - Length, Turns, weather (incoming)"""

# Extract the length of track and no. turns from the wikipedia url given in df_circuit.
# And merge Length and Turns into the dataframe df_circuits

len_turn_data = []

def length_turn(url, cId):
    response = requests.get(url)

    # Parse the HTML content
    soup = BeautifulSoup(response.content, "html.parser")

    # Find the table element
    table = soup.find("table", class_="infobox")
    df = pd.read_html(StringIO(str(table)))[0]

    # If Length/Turns is not available set them to 0.
    try:
        length = df.loc[np.where(df == 'Length')[0][0]].iloc[1]
        turns = df.loc[np.where(df == 'Turns')[0][0]].iloc[1]
    except IndexError:
        length = '0.0000'
        turns = '0'

    # Append the List: [circuitId, Length, Turns]
    len_turn_data.append([cId, length, turns])

# Function to extract Length and Turns for each circuit according to circuitId
for cId, url in zip(df_circuit['circuitId'], df_circuit['url']):
    length_turn(url, cId)

# Convert the Length and Turns column in float and int types
df_len_turn = pd.DataFrame(data=len_turn_data, columns=["circuitId", "Length", "Turns"])

df_len_turn['Length'] = df_len_turn['Length'].str[:5].astype(float)
df_len_turn['Turns'] = df_len_turn['Turns'].str[:2].astype(int)

# Merge the Length & Turns dataframe to df_circuits according to circuitId
df_circuit = df_circuit.merge(df_len_turn, on='circuitId', how='left')

"""# Interactive Map"""

temp = df_results.merge(df_races, on= 'raceId')
temp = temp[['circuitId','driverId',"constructorId","positionOrder","year"]]
temp = df_circuit.merge(temp, on='circuitId')
temp

df_drivers["Driver_name"] = df_drivers["forename"] + ' ' + df_drivers['surname']
temp1 = df_drivers[["Driver_name","driverId"]]
temp = temp.merge(temp1, on= 'driverId')
temp

temp_cons = df_constructor[['constructorId','name']]
temp_cons = temp_cons.rename(columns={'name' : 'Constructor_name'})
temp = temp.merge(temp_cons, on = 'constructorId')
temp

import folium
from ipywidgets import interact, widgets

# Create a Map instance
m = folium.Map(location=[20, 0], zoom_start=2)

# Suppose you have a DataFrame df_pilotes with columns 'circuit_id', 'pilote_name', 'position', 'year', 'name', 'Length', and 'Turns'
# Sort the DataFrame by 'position' in descending order to get the last 5 winners for each circuit
df_pilotes_sorted = temp[temp['positionOrder'] == 1].sort_values(by=['circuitId','year'], ascending=False)

# Get unique years in the dataset
unique_years = sorted(df_pilotes_sorted['year'].unique())

# Group the sorted DataFrame by 'circuit_id' and get the last 5 winners for each circuit
last_5_winners = df_pilotes_sorted.groupby('circuitId').head(5)

# Function to format popup text with HTML table
def get_popup_text(row):
    popup_text = f"<h3 style='margin-bottom: 10px;'>{row['location']}, {row['country']}</h3>"

    # Add circuit information
    popup_text += f"<b>Length:</b> {row['Length']} km<br>"
    popup_text += f"<b>Turns:</b> {row['Turns']}<br>"

    popup_text += f"<h3 style='margin-bottom: 10px;'></h3>"

    popup_text += "<b>Last 5 winners:</b><br>"
    popup_text += "<table style='border-collapse: collapse; width: 100%; margin-top: 10px;'>"
    popup_text += "<tr style='background-color: #f2f2f2;'>"
    popup_text += "<th style='border: 1px solid #dddddd; text-align: left; padding: 8px;'>Driver</th>"
    popup_text += "<th style='border: 1px solid #dddddd; text-align: left; padding: 8px;'>Constructor</th>"
    popup_text += "<th style='border: 1px solid #dddddd; text-align: left; padding: 8px;'>Year</th>"
    popup_text += "</tr>"

    # Get the last 5 winners for the current circuit
    last_5_winners_circuit = last_5_winners[last_5_winners['circuitId'] == row['circuitId']]
    for _, winner_row in last_5_winners_circuit.iterrows():
        popup_text += "<tr>"
        popup_text += f"<td style='border: 1px solid #dddddd; padding: 8px;'>{winner_row['Driver_name']}</td>"
        popup_text += f"<td style='border: 1px solid #dddddd; padding: 8px;'>{winner_row['Constructor_name']}</td>"
        popup_text += f"<td style='border: 1px solid #dddddd; padding: 8px;'>{winner_row['year']}</td>"
        popup_text += "</tr>"

    popup_text += "</table>"

    return popup_text

# Function to filter circuits for a specific year
def filter_circuits(year):
    filtered_circuits = df_pilotes_sorted[df_pilotes_sorted['year'] == year]

    # Clear existing markers on the map
    m = folium.Map(location=[20, 0], zoom_start=2)

    # Iterate over filtered circuits DataFrame to add markers with popups
    for idx, row in filtered_circuits.iterrows():
        popup_text = get_popup_text(row)
        folium.Marker(
            location=[row['lat'], row['lng']],
            popup=folium.Popup(popup_text, max_width=300),
            tooltip=row['name'],  # Display circuit name as tooltip
            icon=folium.Icon(color='red', icon='info-sign')  # Set icon color and style
        ).add_to(m)

    # Add custom CSS to style the popup background color
    css = """
    <style>
    .leaflet-popup-content-wrapper {
        background-color: #333;
        color: #fff;
    }
    </style>
    """
    folium.Popup(css).add_to(m)

    display(m)

# Create dropdown widget for selecting year
year_selector = widgets.Dropdown(
    options=unique_years,
    value=unique_years[-1],  # Default value: latest year
    description='Year:'
)

# Register the function to be called when the year is changed
interact(filter_circuits, year=year_selector)

"""# Data Viz

## Track characteristic

### Altitude effect
"""

df = df_races[['raceId','year','round','circuitId','name']]
df1 = df_circuit[['circuitId','name','alt','Length','Turns']]
df2 = df_results[['raceId','driverId','constructorId','statusId','position']]
df3 = df.merge(df1, on = 'circuitId').rename(columns={'name_x' : 'Grand_prix','name_y' : 'Circuit_name'})
df3 = df3.merge(df2, on='raceId')
df3 = df3.merge(df_status,on= 'statusId')
df_status['status'].unique()

pd.DataFrame(df3.groupby('status')['status'].value_counts())

# DNF caused by engine related failure :
alt_effect = df3[df3['status'].isin(['Transmission','Engine','Overheating','Engine fire','Power loss'])]
alt_effect = alt_effect[alt_effect['year'] >= 2011]
alt_effect = alt_effect.groupby(['Circuit_name','alt'])['status'].count().sort_values(ascending = False).reset_index().head(10)
alt_effect = alt_effect.rename(columns={'status':'Engine related failures'})
alt_effect

import plotly.express as px

fig = px.scatter(alt_effect,
                 x="alt",
                 y="Engine related failures",
                 size="alt",
                 color="Circuit_name",
                 log_x=True,
                 size_max=50,
                 labels={"alt": "Altitude (m)", "Engine related failures": "Failures"},
                 title="Engine Failures vs Altitude by Circuit"
                )

fig.update_traces(marker=dict(line=dict(color='#000000', width=1.5)))

fig.update_layout(
    title_font=dict(size=24, family="Arial"),
    font=dict(size=14, family="Arial"),
    xaxis=dict(
        showgrid=True,
        gridcolor='lightgrey',
        title_text="Altitude (m)",
        title_font=dict(size=18, family="Arial"),
        type="linear",
        showline=True,    # Afficher la ligne de l'axe x
        linewidth=2,      # Épaisseur de la ligne de l'axe x
        linecolor='black' # Couleur de la ligne de l'axe x
    ),
    yaxis=dict(
        showgrid=False,
        title_text="Failures",
        title_font=dict(size=18, family="Arial"),
        showline=True,    # Afficher la ligne de l'axe y
        linewidth=2,      # Épaisseur de la ligne de l'axe y
        linecolor='black' # Couleur de la ligne de l'axe y
    ),
    plot_bgcolor='rgba(255, 255, 255, 0.9)'
)

fig.show()

"""### Length and turns effect"""

import seaborn as sns
import matplotlib.pyplot as plt

t = df3[['position','Length','Turns']].replace('\\N', np.nan)
# Calculer les corrélations
correlation_matrix = t.corr()

# Créer une heatmap avec seaborn
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", annot_kws={"size": 12})
plt.title('Correlation Heatmap')
plt.show()

"""## Teams

Version classement fin de saison (Pour page d'acceuil de l'appli)
"""

import pandas as pd

def get_constructor_standings(year):
    # 1. Filtrer les données pour l'année spécifiée
    races_current_year = df_races[df_races['year'] == year]

    # 2. Identifier le dernier round de cette année
    last_round = races_current_year['round'].max()

    # 3. Filtrer les données pour ce dernier round
    last_round_data = races_current_year[races_current_year['round'] == last_round]

    # 4. Fusionner les données des classements des constructeurs pour le dernier round
    standing = last_round_data.merge(df_constructor_standing, on='raceId')

    constructor = df_constructor[['constructorId','name','nationality']].rename(columns={'name':'F1 Team'})

    standing = standing.merge(constructor,on='constructorId')

    # 5. Trier les données par points des constructeurs dans l'ordre décroissant
    standing = standing.sort_values(by='points', ascending=False)

    return standing[['position', 'F1 Team','points', 'wins']]

# Exemple d'utilisation
# Supposons que vous ayez déjà chargé vos données dans les DataFrames df_races, df_constructor_standing et df_constructor
year = 2023  # Remplacez par l'année souhaitée
constructor_standings = get_constructor_standings(year)
constructor_standings

"""Version choix du classement après la course de notre choix"""

import pandas as pd

def get_constructor_standings(year, round_num):
    # 1. Filtrer les données pour l'année spécifiée
    races_current_year = df_races[(df_races['year'] == year) & (df_races['round'] <= round_num)]

    # 2. Identifier le dernier round jusqu'au round spécifié
    last_round = races_current_year['round'].max()

    # 3. Filtrer les données pour ce round spécifié
    round_data = races_current_year[races_current_year['round'] == round_num]

    # 4. Fusionner les données des classements des constructeurs pour ce round spécifié
    standing = round_data.merge(df_constructor_standing, on='raceId')

    constructor = df_constructor[['constructorId','name','nationality']].rename(columns={'name':'F1 Team'})

    standing = standing.merge(constructor,on='constructorId')

    # 5. Trier les données par points des constructeurs dans l'ordre décroissant
    standing = standing.sort_values(by='points', ascending=False)

    return standing[['position', 'F1 Team', 'points', 'wins']]

# Exemple d'utilisation
year = 2024  # Remplacez par l'année souhaitée
round_num = 5  # Remplacez par le round souhaité
constructor_standings = get_constructor_standings(year, round_num)
constructor_standings

"""Suivi de la progression du classement constructeur

---


"""

import pandas as pd
import matplotlib.pyplot as plt
import random

def plot_constructor_standings(year):
    # Filtrer les données pour l'année spécifiée
    races_current_year = df_races[df_races['year'] == year]

    # Fusionner les données des classements des constructeurs pour toute l'année
    standing = races_current_year.merge(df_constructor_standing, on='raceId')

    constructor = df_constructor[['constructorId','name','nationality']].rename(columns={'name':'F1 Team'})
    standing = standing.merge(constructor,on='constructorId')

    # Trier les données par round
    standing = standing.sort_values(by=['round', 'position'], ascending=True)

    # Définir les couleurs pour les équipes spécifiées
    color_map = {
        'Ferrari': 'red',
        'Mercedes': 'lightblue',
        'Red Bull': 'darkblue',
        'McLaren': 'orange'
    }

    # Créer une figure et un axe
    fig, ax = plt.subplots(figsize=(10, 6))

    # Liste des couleurs pour les équipes non spécifiées
    other_colors = [plt.cm.tab10(i) for i in range(len(standing['F1 Team'].unique()) - len(color_map))]

    # Générer un dictionnaire de couleurs pour les équipes non spécifiées
    other_color_map = {team: other_colors.pop(0) for team in standing['F1 Team'].unique() if team not in color_map}

    # Parcourir chaque constructeur pour tracer sa progression de points
    for team, data in standing.groupby('F1 Team'):
        color = color_map.get(team, other_color_map.get(team, 'gray'))  # Utiliser la couleur spécifiée ou aléatoire
        ax.plot(data['round'], data['points'], label=team, color=color)

    # Ajouter des étiquettes, une légende, un titre, etc.
    ax.set_xlabel('Round')
    ax.set_ylabel('Points')
    ax.set_title('Constructor Standings - Year {}'.format(year))
    ax.legend()

    # Afficher le graphique
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Exemple d'utilisation
# Supposons que vous ayez déjà chargé vos données dans les DataFrames df_races, df_constructor_standing et df_constructor
year = 2023  # Remplacez par l'année souhaitée
plot_constructor_standings(year)

"""Historic overall point

---


"""

import pandas as pd

def calculate_historic_team_wins(year_start):
    """
    Calcule le nombre de victoires par équipe à partir de l'année spécifiée.

    Args:
    - year_start (int): Année à partir de laquelle calculer les victoires.

    Returns:
    - DataFrame: DataFrame contenant le nombre de victoires par équipe.
    """

    # Obtenir les données sur l'année de chaque course
    race_year = df_races[['raceId', 'year']]

    # Fusionner les données sur les résultats des courses avec les données sur les constructeurs et les années de course
    point_per_team = df_results.merge(df_constructor, on="constructorId")
    point_per_team = point_per_team.merge(race_year, on='raceId')

    # Filtrer les données pour inclure uniquement les courses à partir de l'année spécifiée
    point_per_team = point_per_team[(point_per_team['year'] >= year_start)]

    # Filtrer les données pour inclure uniquement les victoires
    point_per_team = point_per_team[(point_per_team['position'] == '1')]

    # Calculer le nombre de victoires par équipe
    historic_wins = pd.DataFrame(point_per_team.groupby('name')['position'].count().sort_values(ascending=False).head(10))
    historic_wins = historic_wins.rename(columns={'position':'Wins'})
    # Retourner le résultat sous forme de DataFrame
    return pd.DataFrame(historic_wins)

# Utilisation de la fonction avec l'année de départ spécifiée
year_start = 2015
historic_wins = calculate_historic_team_wins(year_start)
historic_wins

"""Densité des points par équipe (pour voir où les teams finisses le plus souvent)

---


"""

import seaborn as sns
import matplotlib.pyplot as plt

def plot_team_positions_by_year(year):
    # Sélectionner les données pour l'année spécifiée
    race_year = df_races[['raceId', 'year']]
    position_per_team = df_results.merge(df_constructor, on="constructorId")
    position_per_team = position_per_team.merge(race_year, on='raceId')
    position_per_team = position_per_team[(position_per_team['year'] == year)]

    # Tracer le boxplot avec des couleurs différentes pour chaque équipe
    fig, ax = plt.subplots(figsize=(10, 10))
    sns.boxplot(x="positionOrder", y="name", data=position_per_team,
                ax=ax, palette="colorblind")
    ax.set_title(f"Team's positions in {year}")
    ax.set_xlabel("Position Order")
    ax.set_ylabel("Team")

    # Définir les emplacements des marqueurs sur l'axe des abscisses comme des entiers
    plt.xticks(range(1, position_per_team["positionOrder"].max() + 1,2))

    plt.show()

# Utilisation de la fonction
plot_team_positions_by_year(2023);

"""Percentage of races finished by at least one car of the team

---


"""

import matplotlib.pyplot as plt

def plot_completion_team_rate(driver_name):
    # Filtrer les résultats pour le pilote spécifié
    driver_results = df_results.merge(df_constructor, on='constructorId')
    driver_results = driver_results[driver_results['name'] == driver_name]

    # Calculer le pourcentage de courses terminées
    total_races = len(driver_results)
    completed_races = len(driver_results[driver_results['positionText'] != 'R'])
    completion_rate = (completed_races / total_races) * 100

    # Dessiner la jauge
    fig, ax = plt.subplots(figsize=(6, 6))
    ax.set_title(f'Percentage of races finished by at least one car of  {driver_name}')
    ax.set_aspect('equal')
    ax.pie([completion_rate, 100 - completion_rate], colors=['red', 'lightgrey'], startangle=90,
           wedgeprops=dict(width=0.3, edgecolor='w'))
    ax.text(0, 0, f'{completion_rate:.2f}%', ha='center', va='center', fontsize=20, color='black')
    ax.text(0, -0.3, 'Races finished', ha='center', va='center', fontsize=12, color='black')
    ax.axis('off')
    plt.show()

plot_completion_team_rate('Ferrari')

"""Podiums finishes (à voir si on met une période plutot que seulement dire que c'est depuis par exemple 2000)

---


"""

import matplotlib.pyplot as plt

def plot_podium_team_percentage(driver_name,year):
    # Filtrer les résultats pour le pilote spécifié
    race_year = df_races[['raceId', 'year']]
    driver_results = df_results.merge(df_constructor, on='constructorId')
    driver_results = driver_results.merge(race_year, on = 'raceId')
    driver_results = driver_results[driver_results['name'] == driver_name]
    driver_results = driver_results[driver_results['year'] >= year]

    # Calculer le pourcentage de podiums
    total_races = len(driver_results)
    podium_races = len(driver_results[((driver_results['positionText'] == '1') |
                                      (driver_results['positionText'] == '2') |
                                      (driver_results['positionText'] == '3'))])

    podium_percentage = (podium_races / total_races) * 100

    # Dessiner la jauge
    fig, ax = plt.subplots(figsize=(6, 6))
    ax.set_title(f'Pourcentage de podiums pour {driver_name}')
    ax.set_aspect('equal')
    ax.pie([podium_percentage, 100 - podium_percentage], colors=['red', 'lightgrey'], startangle=90,
           wedgeprops=dict(width=0.3, edgecolor='w'))
    ax.text(0, 0, f'{podium_percentage:.2f}%', ha='center', va='center', fontsize=20, color='black')
    ax.text(0, -0.3, 'Podiums', ha='center', va='center', fontsize=12, color='black')
    ax.axis('off')
    plt.show()

# Exemple d'utilisation avec le pilote Max Verstappen
plot_podium_team_percentage('Ferrari',2000)
plt.show()

"""Correlation entre la position de départ et la position d'arrivé selon les circuits (On voit bien que la position de départ est plus importante sur certaines circuit que d'autres)"""

import pandas as pd

# Supposons que df_races contient les données des courses et df_results contient les résultats des courses.

# Fusionner les résultats avec les données des pilotes et des courses
results_with_race = df_results.merge(df_races, on='raceId')
circuit_name = df_circuit[['circuitId','circuitRef']]
results_with_race = results_with_race.merge(circuit_name, on = 'circuitId')
results_with_race = results_with_race[results_with_race['year'] >= 2021]

# Calculer la corrélation entre la position de départ et la position d'arrivée pour chaque course
correlation_by_race = results_with_race.groupby('circuitRef')[['grid', 'positionOrder']].corr().iloc[0::2, -1].sort_values(ascending=False).head(20)

# Afficher les corrélations
print("Correlation between starting position and finishing position by circuit:")
print(correlation_by_race)

import matplotlib.pyplot as plt

# Tracer le graphique à barres
plt.figure(figsize=(12, 6))
correlation_by_race.plot(kind='bar', color='grey')
plt.xlabel('Circuit')
plt.ylabel('Correlation')
plt.title('Correlation between starting position and finishing position by circuit')
plt.xticks(rotation=45, ha='right', ticks=range(len(correlation_by_race)), labels=correlation_by_race.index.get_level_values(0))
plt.grid(axis='y', alpha=0.2)
plt.show()

"""Mechanic crew performance (pit-stop)"""

import matplotlib.pyplot as plt

t= df_races.merge(df_pit_stops, on='raceId')
t= t.merge(df_drivers, on = 'driverId')
t = t[['raceId','year','round','driverId','milliseconds']]
t = t.merge(df_results[['raceId','driverId','constructorId','positionOrder']], on = ['raceId','driverId'])
t = t.merge(df_constructor[['constructorId','name']], on = 'constructorId')

t['milliseconds'] = t['milliseconds'] / 1000
t = t[t['milliseconds'] <= 60]
t

def boxplot_by_team_for_year(year):
    # Filtrer les données pour l'année spécifiée
    df_year = t[t['year'] == year]

    # Créer une liste unique d'équipes
    teams = df_year['name'].unique()

    # Créer un dictionnaire pour stocker les données par équipe
    team_data = {team: [] for team in teams}

    # Ajouter les données de temps de pit stop pour chaque équipe dans le dictionnaire
    for team in teams:
        team_data[team] = df_year[df_year['name'] == team]['milliseconds']

    # Définir une liste de couleurs pour chaque équipe
    colors = ['blue', 'green', 'red', 'orange', 'pink', 'yellow', 'cyan', 'purple', 'brown', 'grey']

    # Créer un graphique à boîte à moustaches pour chaque équipe
    plt.figure(figsize=(10, 10))
    bp = plt.boxplot(team_data.values(), labels=team_data.keys(), vert=False, patch_artist=True)

    # Ajouter des couleurs aux boîtes à moustaches
    for box, color in zip(bp['boxes'], colors):
        box.set(facecolor=color)

    plt.ylabel('Team')
    plt.xlabel('Pit stop (seconds)')
    plt.title(f'Mechanic crew performance during pit-stops in {year}')
    plt.grid()
    plt.show()

# Utilisation de la fonction avec le dataframe t pour l'année 2023
boxplot_by_team_for_year(2023)

t
results_with_race = t[t['year'] >= 2008]

# Calculer la corrélation entre la position de départ et la position d'arrivée pour chaque course
correlation_by_race = results_with_race[['milliseconds', 'positionOrder']].corr().iloc[0::2, -1].sort_values(ascending=False).head(20)

# Afficher les corrélations
print(correlation_by_race)

"""## Driver

Driver standing at the last race

---
"""

import pandas as pd

def get_driver_standings(year):
    # 1. Filtrer les données pour l'année spécifiée
    races_current_year = df_races[df_races['year'] == year]

    # 2. Identifier le dernier round de cette année
    last_round = races_current_year['round'].max()

    # 3. Filtrer les données pour ce dernier round
    last_round_data = races_current_year[races_current_year['round'] == last_round]

    # 4. Fusionner les données des classements des constructeurs pour le dernier round
    standing = last_round_data.merge(df_driver_standing, on='raceId')

    drivers = df_drivers[['driverId','Driver_name','nationality']]

    standing = standing.merge(drivers,on='driverId')

    # 5. Trier les données par points des constructeurs dans l'ordre décroissant
    standing = standing.sort_values(by='points', ascending=False).sort_values(by='position', ascending=True)

    return standing[['position', 'Driver_name','points', 'wins']]

# Exemple d'utilisation
year = 2023  # Remplacez par l'année souhaitée
driver_standings = get_driver_standings(year)
driver_standings

"""Driver standing at the end of the wished round

---


"""

import pandas as pd

def get_driver_standings(year, round_num):
    # 1. Filtrer les données pour l'année spécifiée
    races_current_year = df_races[(df_races['year'] == year) & (df_races['round'] <= round_num)]

    # 2. Identifier le dernier round jusqu'au round spécifié
    last_round = races_current_year['round'].max()

    # 3. Filtrer les données pour ce round spécifié
    round_data = races_current_year[races_current_year['round'] == round_num]

    # 4. Fusionner les données des classements des constructeurs pour ce round spécifié
    standing = round_data.merge(df_driver_standing, on='raceId')

    drivers = df_drivers[['driverId','Driver_name','nationality']]

    standing = standing.merge(drivers,on='driverId')


    # 5. Trier les données par points des constructeurs dans l'ordre décroissant
    standing = standing.sort_values(by='points', ascending=False).sort_values(by='position', ascending=True)

    return standing[['position', 'Driver_name','points', 'wins']]

# Exemple d'utilisation
year = 2023  # Remplacez par l'année souhaitée
round_num = 20  # Remplacez par le round souhaité
driver_standings = get_driver_standings(year,round_num)
driver_standings

"""Driver championship progression

---


"""

import pandas as pd
import matplotlib.pyplot as plt

def plot_driver_standings(year):
    # Filtrer les données pour l'année spécifiée
    races_current_year = df_races[df_races['year'] == year]

    # Fusionner les données des classements des constructeurs pour toute l'année
    standing = races_current_year.merge(df_driver_standing, on='raceId')

    drivers = df_drivers[['driverId','Driver_name','nationality']]

    standing = standing.merge(drivers,on='driverId')

    # Trier les données par round
    standing = standing.sort_values(by=['round', 'position'], ascending=True)

    # Créer une figure et un axe
    fig, ax = plt.subplots(figsize=(10, 6))

    # Parcourir chaque constructeur pour tracer sa progression de points
    for team, data in standing.groupby('Driver_name'):
        ax.plot(data['round'], data['points'], label=team)

    # Ajouter des étiquettes, une légende, un titre, etc.
    ax.set_xlabel('Round')
    ax.set_ylabel('Points')
    ax.set_title('Drivers Standings - Year {}'.format(year))
    ax.legend()

    # Afficher le graphique
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Exemple d'utilisation
# Supposons que vous ayez déjà chargé vos données dans les DataFrames df_races, df_constructor_standing et df_constructor
year = 2023  # Remplacez par l'année souhaitée
plot_driver_standings(year)

"""Number of wins"""

import pandas as pd

def calculate_historic_driver_wins(year_start):
    """
    Calcule le nombre de victoires par équipe à partir de l'année spécifiée.

    Args:
    - year_start (int): Année à partir de laquelle calculer les victoires.

    Returns:
    - DataFrame: DataFrame contenant le nombre de victoires par équipe.
    """

    # Obtenir les données sur l'année de chaque course
    race_year = df_races[['raceId', 'year']]

    # Fusionner les données sur les résultats des courses avec les données sur les constructeurs et les années de course
    point_per_team = df_results.merge(df_drivers, on="driverId")
    point_per_team = point_per_team.merge(race_year, on='raceId')

    # Filtrer les données pour inclure uniquement les courses à partir de l'année spécifiée
    point_per_team = point_per_team[(point_per_team['year'] >= year_start)]

    # Filtrer les données pour inclure uniquement les victoires
    point_per_team = point_per_team[(point_per_team['position'] == '1')]

    # Calculer le nombre de victoires par équipe
    historic_wins = pd.DataFrame(point_per_team.groupby('Driver_name')['position'].count().sort_values(ascending=False).head(10))
    historic_wins = historic_wins.rename(columns={'position':'Wins'})
    # Retourner le résultat sous forme de DataFrame
    return pd.DataFrame(historic_wins)

# Utilisation de la fonction avec l'année de départ spécifiée
year_start = 2015
historic_wins = calculate_historic_driver_wins(year_start)
historic_wins

"""Carrer points

---


"""

import pandas as pd
import matplotlib.pyplot as plt

def plot_points_by_year(driver_name):
    race_year = df_races[['raceId', 'year']]
    # Agrégation des points par année pour le pilote spécifié
    point_history = df_results.merge(df_drivers, on="driverId")
    point_history = point_history.merge(race_year, on='raceId')
    point_history = point_history[(point_history['Driver_name'] == driver_name)]
    points_by_year = point_history.groupby('year')['points'].sum().reset_index()

    # Création du graphique à barres
    plt.figure(figsize=(10, 6))
    plt.bar(points_by_year['year'], points_by_year['points'], color='red')
    plt.xlabel('Year')
    plt.ylabel('Points')
    plt.title(f'Points scored by {driver_name} during his career')
    plt.xticks(points_by_year['year'])  # Assurez-vous que toutes les années sont affichées sur l'axe des x
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.show()

# Exemple d'utilisation de la fonction avec Max Verstappen
plot_points_by_year('Max Verstappen')

"""Races finished

---


"""

import matplotlib.pyplot as plt

def plot_completion_rate(driver_name):
    # Filtrer les résultats pour le pilote spécifié
    driver_results = df_results.merge(df_drivers, on='driverId')
    driver_results = driver_results[driver_results['Driver_name'] == driver_name]

    # Calculer le pourcentage de courses terminées
    total_races = len(driver_results)
    completed_races = len(driver_results[driver_results['positionText'] != 'R'])
    completion_rate = (completed_races / total_races) * 100

    # Dessiner la jauge
    fig, ax = plt.subplots(figsize=(6, 6))
    ax.set_title(f'Percentage of races finished by {driver_name}')
    ax.set_aspect('equal')
    ax.pie([completion_rate, 100 - completion_rate], colors=['red', 'lightgrey'], startangle=90,
           wedgeprops=dict(width=0.3, edgecolor='w'))
    ax.text(0, 0, f'{completion_rate:.2f}%', ha='center', va='center', fontsize=20, color='black')
    ax.text(0, -0.3, 'Races finished', ha='center', va='center', fontsize=12, color='black')
    ax.axis('off')
    plt.show()

plot_completion_rate('Max Verstappen')

"""Percentage of podium finishes by ...

---


"""

import matplotlib.pyplot as plt

def plot_podium_percentage(driver_name):
    # Filtrer les résultats pour le pilote spécifié
    driver_results = df_results.merge(df_drivers, on='driverId')
    driver_results = driver_results[driver_results['Driver_name'] == driver_name]

    # Calculer le pourcentage de podiums
    total_races = len(driver_results)
    podium_races = len(driver_results[(driver_results['positionText'] == '1') |
                                      (driver_results['positionText'] == '2') |
                                      (driver_results['positionText'] == '3')])
    podium_percentage = (podium_races / total_races) * 100

    # Dessiner la jauge
    fig, ax = plt.subplots(figsize=(6, 6))
    ax.set_title(f'Percentage of podium finishes by {driver_name}')
    ax.set_aspect('equal')
    ax.pie([podium_percentage, 100 - podium_percentage], colors=['red', 'lightgrey'], startangle=90,
           wedgeprops=dict(width=0.3, edgecolor='w'))
    ax.text(0, 0, f'{podium_percentage:.2f}%', ha='center', va='center', fontsize=20, color='black')
    ax.text(0, -0.3, 'Podiums', ha='center', va='center', fontsize=12, color='black')
    ax.axis('off')
    plt.show()

# Exemple d'utilisation avec le pilote Max Verstappen
plot_podium_percentage('Max Verstappen')
plt.show()

"""Lap - time

---


"""

import matplotlib.pyplot as plt
import seaborn as sns

t = df_lap_times.merge(df_races[['raceId','round','name', 'year']], on = 'raceId').merge(df_drivers[["Driver_name","driverId"]], on = 'driverId')
t['milliseconds'] = t['milliseconds']/1000

def plot_lap_times(year, round_num):
    # Filtrer les données pour l'année et le round spécifiés
    filtered_df = t[(t['year'] == year) & (t['round'] == round_num)]

    # Créer le box plot
    plt.figure(figsize=(12, 8))
    sns.boxplot(x='milliseconds', y='Driver_name', data=filtered_df, showfliers=False, palette="colorblind")
    plt.title(f'Lap Times Distribution - Year {year}, Round {"name"}')
    plt.xlabel('Lap Time (seconds)')
    plt.ylabel('Driver')
    plt.tight_layout()
    plt.show()

# Exemple d'utilisation de la fonction avec l'année 2023 et le round 5
plot_lap_times(2023, 5)

t = t.merge(df_results[['raceId','driverId','positionOrder']], on = ['raceId','driverId'])

results_with_race = t[t['year'] >= 2008]

# Calculer la corrélation entre la position de départ et la position d'arrivée pour chaque course
correlation_by_race = results_with_race[['milliseconds', 'positionOrder']].corr().iloc[0::2, -1].sort_values(ascending=False).head(20)

# Afficher les corrélations
print(correlation_by_race)

"""# Weather"""

df_races_post_2008 = df_races[df_races['year'] >= 2008]
df_races_post_2008['year'].value_counts()

df_races_var = df_races_post_2008[['raceId','circuitId','date']]
df_races_var.info()

df_circuit.head()
df_circuit_var = df_circuit[['circuitId','lat','lng','alt']]
df_circuit_var.info()

df_scrap_weather = df_races_var.merge(df_circuit_var, on='circuitId', how='left')
df_scrap_weather

import urllib.request
import urllib.error
import json
import requests
import pandas as pd

# API KEY : 6Q5WBHT28S23QEXLKSTKURBBX

########### -------- Citation-------- ###########
# Visual Crossing Corporation. (2022)). Visual Crossing Weather (2012-2021). [API]. Retrieved from https://www.visualcrossing.com/
# The company is Visual Crossing and the data service name is Visual Crossing Weather. The URL is https://www.visualcrossing.com/

# Loop through the dataframe to get the relevant information, put this into the API retrieval URl and writing it to the existing dataframe
data_to_add = []

for i, row in df_scrap_weather.iterrows():
    lat = str(row['lat'])
    lon = str(row['lng'])
    time_stamp = str(row['date'])
    BaseUrl = "https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/"
    EndUrl = "?unitGroup=metric&elements=datetime%2Ctempmax%2Ctempmin%2Ctemp%2Cdew%2Chumidity%2Cprecip%2Cprecipprob%2Cprecipcover%2Cpreciptype%2Cwindspeed%2Cwinddir%2Cvisibility&include=days&key=6Q5WBHT28S23QEXLKSTKURBBX&contentType=json"
    url = BaseUrl + lat + "%2C" + lon + "/" + time_stamp + "/" + time_stamp + EndUrl
    response = requests.get(url)
    data = json.loads(response.text)
    data = data["days"]
    dict = {k:v for e in data for (k,v) in e.items()}
    for key in dict:
        df_scrap_weather.loc[i,key] = dict[key]
    print(i)

# Ajouter les données à DataFrame après la boucle
df_new_data = pd.DataFrame(data_to_add)

########### -------- Print and Save Dataset -------- ###########
# print(df_location)
# df_location.to_csv("weather_data.csv")



"""# Merging"""

df_final = df_results.merge(df_races[['raceId','round','year','name','circuitId']], on = 'raceId') #merging results info and races info
df_final = df_final.merge(df_circuit[['circuitId','name','location','country','lat','lng','alt']], on = 'circuitId').rename(columns={'name_x' : 'Grand Prix', 'name_y' : 'Circuit_name', 'grid' : 'Starting position'}) #adding circuit info
df_final = df_final.merge(df_drivers[['driverId','Driver_name','nationality','dob']], on='driverId').rename(columns={'dob':'Date_of_birth'}) #adding driver info
df_final = df_final.merge(df_constructor[['constructorId','name']], on='constructorId') #adding constructor info
df_final = df_final.merge(df_driver_standing[['raceId','driverId','position','wins']],how = 'left', on= ['raceId','driverId']).rename(columns={'position_y' : 'current_driver_championship_position', 'wins' : 'driver_wins_after_race(season)'})
df_final = df_final.merge(df_constructor_standing[['raceId', 'constructorId','position','wins']],how='left', on = ['raceId','constructorId']).rename(columns={'position' : 'current_team_championship_position', 'wins' : 'team_wins_after_race(season)'})

df_final = df_final[['raceId','year','round','driverId','Driver_name','nationality','Date_of_birth','constructorId','name','Starting position','positionOrder','circuitId','Circuit_name','alt']].sort_values(by=['year','round'])

"""## Features engineering

### Podium rate (last season)
"""

df_final['Top 3 Finish'] = df_final['positionOrder'].le(3).astype(int)

# Calculating the total number of races and top 3 finishes for each driver in each year
driver_yearly_stats = df_final.groupby(['year', 'driverId']).agg(
    Total_Races=('raceId', 'nunique'),
    Top_3_Finishes=('Top 3 Finish', 'sum')
).reset_index()


# Calculating podium rate for each driver in each year
driver_yearly_stats['Driver Podium rate (This Year)'] = (driver_yearly_stats['Top_3_Finishes'] / driver_yearly_stats['Total_Races'])

# Shifting the driver percentages to the next year for last year's data
driver_last_year_stats = driver_yearly_stats.copy()
driver_last_year_stats['year'] += 1
driver_last_year_stats = driver_last_year_stats.rename(columns={'Driver Podium rate (This Year)': 'Driver Podium rate (Last Year)'})

df_final = df_final.merge(driver_last_year_stats[['year', 'driverId', 'Driver Podium rate (Last Year)']], on=['year', 'driverId'], how='left')

df_final['Driver Podium rate (Last Year)'] = df_final['Driver Podium rate (Last Year)'].fillna(0)

"""Bof jsuis pas sur pour les équipes"""

## Calculating mean of top 3 finishes percentages for the two drivers in each constructor last year
#constructor_last_year_stats = df_final.groupby(['year', 'constructorId', 'round']).agg(
#    Sum_Top_3_Finishes_Last_Year=('Driver Podium rate (Last Year)', 'sum')
#).reset_index()


# Calculating the percentage of top 3 finishes for each constructor last year
#constructor_last_year_stats['Team podium rate (Last Year)'] = constructor_last_year_stats["Sum_Top_3_Finishes_Last_Year"]/2

#df_final = df_final.merge(constructor_last_year_stats[['year', 'constructorId', 'round', 'Team podium rate (Last Year)']], on=['year', 'constructorId', 'round'], how='left')

#df_final.tail(20)

"""### Podium rate (until last race)"""

# Creating a function to calculate the top 3 finish percentage before the current round for drivers
def podium_rate_until_last_race(current, df_final):
    # Filter for races in the same year, for the same driver, but in earlier rounds
    previous_races = df_final[(df_final['year'] == current['year']) & (df_final['driverId'] == current['driverId']) & (df_final['round'] < current['round'])]
    if len(previous_races) == 0:## First race of the year
      return pd.NA

    total_races = previous_races['raceId'].nunique()
    top_3_finishes = previous_races['Top 3 Finish'].sum()

    # Calculate the percentage
    return (top_3_finishes / total_races) if total_races > 0 else pd.NA

# Apply the function to each row in the DataFrame
df_final['Driver podium rate (This Year until last race)'] = df_final.apply(lambda current: podium_rate_until_last_race(current, df_final), axis=1)

"""Vu que on a pas d'historique à la première course, on prend le taux de podium à la dernière course de la saison dernière

---


"""

for index, row in df_final.iterrows():
    if pd.isna(row['Driver podium rate (This Year until last race)']):
        previous_season = row['year'] - 1
        races_previous_season = df_final[(df_final['year'] == previous_season) & (df_final['driverId'] == row['driverId'])]
        if len(races_previous_season) > 0:
            last_race_previous_season = races_previous_season.iloc[-1]
            df_final.at[index, 'Driver podium rate (This Year until last race)'] = last_race_previous_season['Driver podium rate (This Year until last race)']
        else:
            df_final.at[index, 'Driver podium rate (This Year until last race)'] = 0

df_final['Driver podium rate (This Year until last race)'] = df_final['Driver podium rate (This Year until last race)'].fillna(0)

"""### Last race position"""

# Créer la colonne 'last_race_result' avec les résultats du round précédent
df_final['last_race_result'] = df_final.groupby(['year','driverId'])['positionOrder'].shift(1)

for index, row in df_final.iterrows():
    if pd.isna(row['last_race_result']):
        previous_season = row['year'] - 1
        races_previous_season = df_final[(df_final['year'] == previous_season) & (df_final['driverId'] == row['driverId'])]
        if len(races_previous_season) > 0:
            last_race_previous_season = races_previous_season.iloc[-1]
            df_final.at[index, 'last_race_result'] = last_race_previous_season['positionOrder']
        else:
            df_final.at[index, 'last_race_result'] = 0 # Premier course de la carrière

df_final

"""### Average finish position during last year

Driver

---
"""

# Calculating the total number of races and top 3 finishes for each driver in each year
driver_yearly_stats = df_final.groupby(['year', 'driverId']).agg(
    Avg_pos=('positionOrder', 'mean')
).reset_index()


# Calculating podium rate for each driver in each year
driver_yearly_stats['Avg position (This Year)'] = driver_yearly_stats['Avg_pos']

# Shifting the driver percentages to the next year for last year's data
driver_last_year_stats = driver_yearly_stats.copy()
driver_last_year_stats['year'] += 1
driver_last_year_stats = driver_last_year_stats.rename(columns={'Avg position (This Year)': 'Avg Driver position (Last Year)'})

df_final = df_final.merge(driver_last_year_stats[['year', 'driverId', 'Avg Driver position (Last Year)']], on=['year', 'driverId'], how='left')

df_final['Avg Driver position (Last Year)'] = df_final['Avg Driver position (Last Year)'].fillna(0)

"""Constructor

---


"""

# Calculating the total number of races and top 3 finishes for each driver in each year
driver_yearly_stats = df_final.groupby(['year', 'constructorId']).agg(
    Avg_pos=('positionOrder', 'mean')
).reset_index()


# Calculating podium rate for each driver in each year
driver_yearly_stats['Avg position (This Year)'] = driver_yearly_stats['Avg_pos']

# Shifting the driver percentages to the next year for last year's data
driver_last_year_stats = driver_yearly_stats.copy()
driver_last_year_stats['year'] += 1
driver_last_year_stats = driver_last_year_stats.rename(columns={'Avg position (This Year)': 'Avg Team position (Last Year)'})

df_final = df_final.merge(driver_last_year_stats[['year', 'constructorId', 'Avg Team position (Last Year)']], on=['year', 'constructorId'], how='left')

df_final['Avg Team position (Last Year)'] = df_final['Avg Team position (Last Year)'].fillna(0)

"""### Average finish position until last race (current season)

Driver

---
"""

def Avg_pos_until_last_race(current, df_final):
    # Filter for races in the same year, for the same driver, but in earlier rounds
    previous_races = df_final[(df_final['year'] == current['year']) & (df_final['driverId'] == current['driverId']) & (df_final['round'] < current['round'])]
    if len(previous_races) == 0:## First race of the year
      return pd.NA

    total_races = previous_races['raceId'].nunique()
    total_point = previous_races['positionOrder'].sum()

    # Calculate the percentage
    return (total_point / total_races) if total_races > 0 else pd.notna

# Apply the function to each row in the DataFrame
df_final['Avg driver position (This Year until last race)'] = df_final.apply(lambda current: Avg_pos_until_last_race(current, df_final), axis=1)

for index, row in df_final.iterrows():
    if pd.isna(row['Avg driver position (This Year until last race)']):
        previous_season = row['year'] - 1
        races_previous_season = df_final[(df_final['year'] == previous_season) & (df_final['driverId'] == row['driverId'])]
        if len(races_previous_season) > 0:
            last_race_previous_season = races_previous_season.iloc[-1]
            df_final.at[index, 'Avg driver position (This Year until last race)'] = last_race_previous_season['Avg driver position (This Year until last race)']
        else:
            df_final.at[index, 'Avg driver position (This Year until last race)'] = 0

df_final['Avg driver position (This Year until last race)'] = df_final['Avg driver position (This Year until last race)'].fillna(0)

"""Team

---


"""

# Creating a function to calculate the top 3 finish percentage before the current round for drivers
def Avg_Teampos_until_last_race(current, df_final):
    # Filter for races in the same year, for the same driver, but in earlier rounds
    previous_races = df_final[(df_final['year'] == current['year']) & (df_final['constructorId'] == current['constructorId']) & (df_final['round'] < current['round'])]
    if len(previous_races) == 0:## First race of the year
      return 0

    total_races = (previous_races['raceId'].nunique()) * 2
    total_point = previous_races['positionOrder'].sum()

    # Calculate the percentage
    return (total_point / total_races) if total_races > 0 else 0

# Apply the function to each row in the DataFrame
df_final['Avg Team position (This Year until last race)'] = df_final.apply(lambda current: Avg_Teampos_until_last_race(current, df_final), axis=1)

for index, row in df_final.iterrows():
    if pd.isna(row['Avg Team position (This Year until last race)']):
        previous_season = row['year'] - 1
        races_previous_season = df_final[(df_final['year'] == previous_season) & (df_final['constructorId'] == row['constructorId'])]
        if len(races_previous_season) > 0:
            last_race_previous_season = races_previous_season.iloc[-1]
            df_final.at[index, 'Avg Team position (This Year until last race)'] = last_race_previous_season['Avg Team position (This Year until last race)']
        else:
            df_final.at[index, 'Avg Team position (This Year until last race)'] = 0

df_final['Avg Team position (This Year until last race)'] = df_final['Avg Team position (This Year until last race)'].fillna(0)

"""### Age during the race"""

# Fonction pour extraire l'année de la date de naissance
def extraire_annee(date_naissance):
    return int(date_naissance.split('-')[0])

# Appliquer la fonction pour extraire l'année de 'Date_of_birth'
df_final['Yearofbirth'] = df_final['Date_of_birth'].apply(extraire_annee)

# Calculer l'âge en soustrayant l'année de naissance de 'year'
df_final['Age at race start'] = df_final['year'] - df_final['Yearofbirth']

"""### Experience (Number of race before the current race)"""

df_final.sort_values(by=['driverId', 'year', 'round'], inplace=True)

# Création d'une nouvelle colonne pour stocker le nombre de courses précédentes pour chaque pilote
df_final['Experience'] = 0

# Calcul du nombre de courses précédentes pour chaque pilote
for driver_id in df_final['driverId'].unique():
    driver_index = df_final['driverId'] == driver_id
    df_final.loc[driver_index, 'Experience'] = df_final[driver_index].groupby('driverId').cumcount()

# Réorganiser le DataFrame pour revenir à l'ordre d'origine
df_final.sort_index(inplace=True)

df_final.to_csv('out.csv')

"""# Modelling

## Modelling without features engineering
"""

df_final['Top 3 Finish'] = df_final['Top 3 Finish'].astype('int64')

df_encoded = df_final.drop(["raceId","positionOrder","Driver_name","Date_of_birth",'name',"Circuit_name",'Yearofbirth'
                            ,"Age at race start","alt","Driver Podium rate (Last Year)","Driver podium rate (This Year until last race)"
                            ,"last_race_result","Avg Driver position (Last Year)","Avg Team position (Last Year)"
                            ,"Avg driver position (This Year until last race)","Avg Team position (This Year until last race)"], axis = 1)

import seaborn as sns
plt.figure(figsize=(10,10))
sns.heatmap(df_encoded.corr(),annot=True)
plt.show()

df_encoded.info()

from sklearn.preprocessing import OneHotEncoder
import pandas as pd

# Supposons que vous avez déjà importé votre DataFrame df_final

# Sélectionnez les colonnes à encoder
columns_to_encode = ["circuitId", 'constructorId', "driverId", "nationality"]

# Créez une instance de OneHotEncoder
encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')

# Adapter et transformer les colonnes sélectionnées
encoded_data = encoder.fit_transform(df_encoded[columns_to_encode])

# Créez un DataFrame avec les données encodées
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(columns_to_encode))

# Supprimez les colonnes encodées du DataFrame d'origine
df_encoded.drop(columns=columns_to_encode, inplace=True)

# Concaténez le DataFrame original avec le DataFrame encodé
df_final_encoded = pd.concat([df_encoded, encoded_df], axis=1)

# Create a list of columns excluding the one to move
cols = [col for col in df_final_encoded.columns if col != 'Top 3 Finish']

# Append the column to the end of the DataFrame
df_final_encoded = df_final_encoded[cols + ['Top 3 Finish']]

train_df = df_final_encoded[(df_final_encoded["year"] >= 2010) & (df_final_encoded["year"] <= 2022)]
test_df = df_final_encoded[(df_final_encoded["year"] == 2023)]


X_train = train_df[train_df.columns.tolist()[:-1]].values
y_train = train_df['Top 3 Finish'].values


X_test = test_df[train_df.columns.tolist()[:-1]].values
y_test = test_df['Top 3 Finish'].values

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

len(X_train)

"""### Logistic"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score

# Normaliser les caractéristiques
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


# Créer un modèle de régression logistique
model = LogisticRegression(random_state=42, max_iter=1000)

# Définir la grille des hyperparamètres à rechercher
param_grid = {
    'C': [0.0001],  # Régularisation
    'penalty': ['l2'],  # Type de pénalisation
    'solver': ['liblinear']  # Solveur à utiliser
}

# Définir les métriques à utiliser
scoring = {
    'f1': make_scorer(f1_score),
    'recall': make_scorer(recall_score)
}

# Créer l'objet GridSearchCV
grid_search = GridSearchCV(model, param_grid, cv=5, scoring=scoring,refit='f1',verbose=1, n_jobs=-1)

# Exécuter la recherche d'hyperparamètres sur l'ensemble d'entraînement
grid_search.fit(X_train, y_train)

# Afficher les meilleurs paramètres et le meilleur score
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)

# Utiliser le meilleur modèle pour faire des prédictions sur l'ensemble de test
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

# Évaluer les performances du meilleur modèle
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

# Afficher les performances
print("\nAccuracy:", accuracy)
print("\nConfusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

import numpy as np
import pandas as pd
import optuna
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Normaliser les caractéristiques
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

def objective(trial):
    # Définir les hyperparamètres à optimiser
    C = trial.suggest_loguniform('C', 1e-5, 100)
    penalty = trial.suggest_categorical('penalty', ['l2'])
    solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs',"saga"])

    # Créer le modèle de régression logistique avec les hyperparamètres
    model = LogisticRegression(random_state=42, max_iter=1000, C=C, penalty=penalty, solver=solver)

    # Entraîner le modèle
    model.fit(X_train, y_train)

    # Prédire sur l'ensemble de validation
    y_pred = model.predict(X_test)

    # Calculer le score f1
    recall = recall_score(y_test, y_pred)

    return recall


# Créer l'étude Optuna
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# Afficher les meilleurs paramètres et le meilleur score
print("Best Parameters:", study.best_params)
print("Best Score:", study.best_value)

# Utiliser le meilleur modèle pour faire des prédictions sur l'ensemble de test
best_model = LogisticRegression(random_state=42, max_iter=1000, **study.best_params)
best_model.fit(X_train, y_train)
y_pred = best_model.predict(X_test)

# Évaluer les performances du meilleur modèle
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

# Afficher les performances
print("\nAccuracy:", accuracy)
print("\nConfusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)
disp.plot()
plt.show()

from sklearn.metrics import roc_auc_score
probabilities = best_model.predict_proba(X_test)
auc = roc_auc_score(y_test, probabilities[:, 1])  # Calculate AUC-ROC
print(auc)

"""## Modelling with "Driver Podium rate (Last Year)","Driver podium rate (This Year until last race)"
"""

df_encoded = df_final.drop(["raceId","positionOrder","Driver_name","Date_of_birth",'name',"Circuit_name",'Yearofbirth'
                            ,"Age at race start","alt"
                            ,"last_race_result","Avg Driver position (Last Year)","Avg Team position (Last Year)"
                            ,"Avg driver position (This Year until last race)","Avg Team position (This Year until last race)"], axis = 1)

df_final_encoded = pd.get_dummies(df_encoded, columns= ["circuitId", 'constructorId', "driverId", "nationality"])

# Create a list of columns excluding the one to move
cols = [col for col in df_final_encoded.columns if col != 'Top 3 Finish']

# Append the column to the end of the DataFrame
df_final_encoded = df_final_encoded[cols + ['Top 3 Finish']]

train_df = df_final_encoded[(df_final_encoded["year"] >= 2010) & (df_final_encoded["year"] <= 2022)]
test_df = df_final_encoded[(df_final_encoded["year"] == 2023)]


X_train = train_df[train_df.columns.tolist()[:-1]].values
y_train = train_df['Top 3 Finish'].values


X_test = test_df[train_df.columns.tolist()[:-1]].values
y_test = test_df['Top 3 Finish'].values

"""### Logistic"""

import numpy as np
import pandas as pd
import optuna
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Normaliser les caractéristiques
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

def objective(trial):
    # Définir les hyperparamètres à optimiser
    C = trial.suggest_loguniform('C', 1e-5, 100)
    penalty = trial.suggest_categorical('penalty', ['l2'])
    solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs',"saga"])

    # Créer le modèle de régression logistique avec les hyperparamètres
    model = LogisticRegression(random_state=42, max_iter=1000, C=C, penalty=penalty, solver=solver)

    # Entraîner le modèle
    model.fit(X_train, y_train)

    # Prédire sur l'ensemble de validation
    y_pred = model.predict(X_test)

    # Calculer le score f1
    recall = recall_score(y_test, y_pred)

    return recall


# Créer l'étude Optuna
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# Afficher les meilleurs paramètres et le meilleur score
print("Best Parameters:", study.best_params)
print("Best Score:", study.best_value)

# Utiliser le meilleur modèle pour faire des prédictions sur l'ensemble de test
best_model = LogisticRegression(random_state=42, max_iter=1000, **study.best_params)
best_model.fit(X_train, y_train)
y_pred = best_model.predict(X_test)

# Évaluer les performances du meilleur modèle
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

# Afficher les performances
print("\nAccuracy:", accuracy)
print("\nConfusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

import numpy as np
import pandas as pd
import optuna
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Normaliser les caractéristiques
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)


def objective(trial):
    # Définir les hyperparamètres à optimiser
    C = trial.suggest_loguniform('C', 1e-5, 100)
    penalty = trial.suggest_categorical('penalty', ['l2'])
    solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs',"saga"])

    # Créer le modèle de régression logistique avec les hyperparamètres
    model = LogisticRegression(random_state=42, max_iter=1000, C=C, penalty=penalty, solver=solver)

    # Entraîner le modèle
    model.fit(X_train, y_train)

    # Prédire sur l'ensemble de validation
    y_pred = model.predict(X_test)

    # Calculer le score f1
    f1 = f1_score(y_test, y_pred)

    return f1


# Créer l'étude Optuna
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# Afficher les meilleurs paramètres et le meilleur score
print("Best Parameters:", study.best_params)
print("Best Score:", study.best_value)

# Utiliser le meilleur modèle pour faire des prédictions sur l'ensemble de test
best_model = LogisticRegression(random_state=42, max_iter=1000, **study.best_params)
best_model.fit(X_train, y_train)
y_pred = best_model.predict(X_test)

# Évaluer les performances du meilleur modèle
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

# Afficher les performances
print("\nAccuracy:", accuracy)
print("\nConfusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

import numpy as np
import pandas as pd
import optuna
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import recall_score

# Normaliser les caractéristiques
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

# Fonction objective avec validation croisée
def objective(trial):
    # Définir les hyperparamètres à optimiser
    C = trial.suggest_loguniform('C', 1e-5, 100)
    penalty = trial.suggest_categorical('penalty', ['l2'])
    solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs',"saga"])

    # Créer le modèle de régression logistique avec les hyperparamètres
    model = LogisticRegression(random_state=42, max_iter=1000, C=C, penalty=penalty, solver=solver)

    # Validation croisée
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    f1s = cross_val_score(model, X_train, y_train, cv=skf, scoring='f1')

    # Calculer la moyenne des rappels pour les différents plis
    f1_mean = np.mean(f1s)

    return f1_mean

# Créer l'étude Optuna
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# Afficher les meilleurs paramètres et le meilleur score
print("Best Parameters:", study.best_params)
print("Best Score:", study.best_value)

# Utiliser le meilleur modèle pour faire des prédictions sur l'ensemble de test
best_model = LogisticRegression(random_state=42, max_iter=1000, **study.best_params)
best_model.fit(X_train, y_train)
y_pred = best_model.predict(X_test)

# Évaluer les performances du meilleur modèle
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

# Afficher les performances
print("\nRecall:", recall)
print("\nF1_score:", f1)
print("\nAccuracy:", accuracy)
print("\nConfusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

"""## SVM"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score
from imblearn.over_sampling import SMOTE

# Normaliser les caractéristiques
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Utilisation de SMOTE pour suréchantillonner la classe minoritaire
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)

# Créer un modèle SVM
svm_model = SVC(random_state=42)

param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto']
}

# Définir les métriques à utiliser
scoring = {
    'f1': make_scorer(f1_score),
    'recall': make_scorer(recall_score)
}

# Créer l'objet GridSearchCV
svm_grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring=scoring, refit='recall', verbose=1, n_jobs=-1)

# Exécuter la recherche d'hyperparamètres sur l'ensemble d'entraînement
svm_grid_search.fit(X_train_resampled, y_train_resampled)

# Afficher les meilleurs paramètres et le meilleur score
print("Best Parameters:", svm_grid_search.best_params_)
print("Best Score:", svm_grid_search.best_score_)

# Utiliser le meilleur modèle pour faire des prédictions sur l'ensemble de test
best_svm_model = svm_grid_search.best_estimator_
y_pred_svm = best_svm_model.predict(X_test_scaled)

# Évaluer les performances du meilleur modèle
accuracy_svm = accuracy_score(y_test, y_pred_svm)
conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)
class_report_svm = classification_report(y_test, y_pred_svm)

# Afficher les performances
print("\nAccuracy:", accuracy_svm)
print("\nConfusion Matrix:\n", conf_matrix_svm)
print("\nClassification Report:\n", class_report_svm)

"""## K - neighbors"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
# Normaliser les caractéristiques
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Utilisation de SMOTE pour suréchantillonner la classe minoritaire
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)

# Créer un modèle KNN
knn_model = KNeighborsClassifier()

# Définir la grille des hyperparamètres à rechercher
param_grid = {
    'n_neighbors': [3,4, 5, 7],  # Nombre de voisins à considérer
    'weights': ['uniform', 'distance'],  # Méthode de pondération des voisins
    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  # Algorithme utilisé pour calculer les voisins
}

# Définir les métriques à utiliser
scoring = {
    'f1': make_scorer(f1_score),
    'recall': make_scorer(recall_score)
}

# Créer l'objet GridSearchCV
knn_grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring=scoring, refit='recall', verbose=1, n_jobs=-1)

# Exécuter la recherche d'hyperparamètres sur l'ensemble d'entraînement
knn_grid_search.fit(X_train_resampled, y_train_resampled)

# Afficher les meilleurs paramètres et le meilleur score
print("Best Parameters:", knn_grid_search.best_params_)
print("Best Score:", knn_grid_search.best_score_)

# Utiliser le meilleur modèle pour faire des prédictions sur l'ensemble de test
best_knn_model = knn_grid_search.best_estimator_
y_pred_knn = best_knn_model.predict(X_test_scaled)

# Calculer les probabilités prédites pour la courbe ROC
y_prob_knn = best_knn_model.predict_proba(X_test_scaled)[:, 1]

# Évaluer les performances du meilleur modèle
accuracy_knn = accuracy_score(y_test, y_pred_knn)
conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)
class_report_knn = classification_report(y_test, y_pred_knn)

# Afficher les performances
print("\nAccuracy:", accuracy_knn)
print("\nConfusion Matrix:\n", conf_matrix_knn)
print("\nClassification Report:\n", class_report_knn)

# Calculer la courbe ROC et l'AUC
fpr, tpr, thresholds = roc_curve(y_test, y_prob_knn)
auc = roc_auc_score(y_test, y_prob_knn)

# Afficher la courbe ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='orange', label='ROC Curve (AUC = %0.2f)' % auc)
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()


df_final['Winner'] = df_final['positionOrder'].le(1).astype(int)

corr_with_new_variable = df_final[["Top 3 Finish",
                                   "Winner",
                                   "positionOrder",
                                   "year",
                                   "Driver Podium rate (Last Year)",
                                   "Driver podium rate (This Year until last race)",
                                   "Avg Driver position (Last Year)",
                                   "Avg Team position (Last Year)",
                                   "Avg driver position (This Year until last race)",
                                   "Avg Team position (This Year until last race)",
                                   "last_race_result",
                                   "Experience"]]
corr_with_new_variable = corr_with_new_variable[corr_with_new_variable["year"] >= 2012]
corr_matrix = corr_with_new_variable.corr()

# Extraire les corrélations des variables avec "Top 3 Finish" et "Winner"
corr_with_top3_finish = corr_matrix["positionOrder"].sort_values(ascending=False)
corr_with_winner = corr_matrix["Top 3 Finish"].sort_values(ascending=False)

train = df_final[(df_final["year"] >= 2012) & (df_final["year"] <= 2022)]
test = df_final[(df_final["year"] == 2023)]

t = df_final[(df_final["year"] >= 2012) & (df_final["year"] <= 2022)]
t["Winner"].value_counts()

top3_finish_counts = t["Winner"].value_counts()

# Créez un barplot
plt.figure(figsize=(10, 6))
top3_finish_counts.plot(kind='bar', color = 'grey')
plt.title('Counts of Winner')
plt.xlabel('Winner')
plt.ylabel('Count')
plt.xticks(rotation=0)  # Rotation des étiquettes des x pour une meilleure lisibilité
plt.show()

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X,y_resampled = smote.fit_resample(t[["year","positionOrder"]],t["Winner"])

y_resampled.value_counts()

top3_finish_counts = y_resampled.value_counts()

# Créez un barplot
plt.figure(figsize=(10, 6))
top3_finish_counts.plot(kind='bar', color = 'grey')
plt.title('Counts of Winner')
plt.xlabel('Winner')
plt.ylabel('Count')
plt.xticks(rotation=0)  # Rotation des étiquettes des x pour une meilleure lisibilité
plt.show()